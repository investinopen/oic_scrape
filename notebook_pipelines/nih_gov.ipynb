{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# National Institutes of Health\n",
    "\n",
    "Data from the National Institutes of Health via their [RePORTER](https://projectreporter.nih.gov/reporter.cfm) system.\n",
    "\n",
    "Data is obtained via their RePORTER [API](https://api.reporter.nih.gov/). This API can be updated on a weekly basis (Monday mornings around 10am EST) to retrieve the latest data. When weekly updates are applied following the initial data backfill, this can be extremely up-to-date.\n",
    "\n",
    "[Data Dictionary](https://api.reporter.nih.gov/documents/Data%20Elements%20for%20RePORTER%20Project%20API_V2.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import datetime\n",
    "from datetime import timedelta\n",
    "from typing import List, Dict, Any, Optional\n",
    "import requests\n",
    "import warnings\n",
    "from requests.adapters import HTTPAdapter\n",
    "from urllib3.util.retry import Retry\n",
    "from requests_cache import CachedSession\n",
    "import duckdb\n",
    "from oic_scrape.items import AwardItem, AwardParticipant\n",
    "import polars as pl\n",
    "import dateutil\n",
    "from attrs import asdict\n",
    "\n",
    "# Test if we are in a notebook, load right tqdm\n",
    "try:\n",
    "    get_ipython()  # type: ignore\n",
    "    from tqdm.notebook import tqdm\n",
    "except NameError:\n",
    "    from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# minimum start date is 2011-01-01 when using date_added api field\n",
    "START_DATE = \"2015-01-01\"\n",
    "END_DATE = datetime.datetime.now().strftime(\"%Y-%m-%d\")\n",
    "OUTPUT_LOCATION = \"data/nih.gov_grants.jsonl\"\n",
    "\n",
    "## NEVER COMMIT WITH THIS SET TO TRUE\n",
    "USE_CACHE = \"True\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "START_DATE = '2022-10-01'\n",
    "END_DATE = '2023-10-01'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Parameter Clean-Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {}\n",
    "# Validate and convert START_DATE\n",
    "try:\n",
    "    parameters[\"start_date\"] = datetime.datetime.strptime(START_DATE, \"%Y-%m-%d\").date()\n",
    "except ValueError:\n",
    "    raise ValueError(\"Invalid START_DATE format. Please use the format 'YYYY-MM-DD'.\")\n",
    "if parameters[\"start_date\"] < datetime.datetime(2009, 1, 1).date():\n",
    "    raise ValueError(\"START_DATE is too early. Please use a date after 2009-01-01.\")\n",
    "\n",
    "# Validate and convert END_DATE\n",
    "try:\n",
    "    parameters[\"end_date\"] = datetime.datetime.strptime(END_DATE, \"%Y-%m-%d\").date()\n",
    "except ValueError:\n",
    "    raise ValueError(\"Invalid END_DATE format. Please use the format 'YYYY-MM-DD'.\")\n",
    "\n",
    "# Ensure END DATE > START_DATE\n",
    "if parameters[\"end_date\"] <= parameters[\"start_date\"]:\n",
    "    raise ValueError(\"END_DATE must be greater than START_DATE.\")\n",
    "\n",
    "\n",
    "# Validate and convert USE_CACHE\n",
    "if USE_CACHE.lower() not in [\"true\", \"false\"]:\n",
    "    raise ValueError(\"Invalid USE_CACHE value. Please use 'True' or 'False'.\")\n",
    "parameters[\"use_cache\"] = USE_CACHE.lower() == \"true\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## HTTP Configuration\n",
    "\n",
    "# Cache for development use only\n",
    "if parameters[\"use_cache\"]:\n",
    "    session = CachedSession(\n",
    "        \"cache.sqlite\",\n",
    "        backend=\"sqlite\",\n",
    "        allowable_methods=(\"GET\", \"POST\"),\n",
    "        allowable_codes=(200, 404),\n",
    "    )\n",
    "else:\n",
    "    session = requests.Session()\n",
    "retry = Retry(connect=5, backoff_factor=1.5)\n",
    "adapter = HTTPAdapter(max_retries=retry)\n",
    "session.mount(\"http://\", adapter)\n",
    "session.mount(\"https://\", adapter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NIH API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NihApi:\n",
    "    API_URL: str = \"https://api.reporter.nih.gov/v2/projects/search\"\n",
    "    last_request_timestamp: Optional[datetime.datetime] = None\n",
    "    follow_rate_limit: bool = True\n",
    "\n",
    "    def __init__(self, follow_rate_limit: bool = True):\n",
    "        self.follow_rate_limit = follow_rate_limit\n",
    "\n",
    "    def projects_search(\n",
    "        self,\n",
    "        payload: Dict[Any, Any],\n",
    "        offset: Optional[int] = None,\n",
    "        limit: Optional[int] = None,\n",
    "    ) -> Dict[Any, Any]:\n",
    "        \"\"\"\n",
    "        Calls the NIH RePORTER API to get project data.\n",
    "\n",
    "        Args:\n",
    "            payload (Dict[Any, Any]): Allows for manual specification of the complete search payload.\n",
    "                Documentation at https://api.reporter.nih.gov/?urls.primaryName=V2.0\n",
    "            offset (int, optional): The offset for the API request. Defaults to None (0). Maximum is 14,999.\n",
    "            limit (int, optional): The maximum number of results to return. Min = 1, Max = 500\n",
    "                Defaults to 50 (when not specified), but is more efficient at 500.\n",
    "\n",
    "        Returns:\n",
    "            Dict[Any, Any]: The response from the API request.\n",
    "\n",
    "        Raises:\n",
    "            ValueError: If the API request fails or returns an error.\n",
    "        \"\"\"\n",
    "\n",
    "        # Check for overlaps between the payload dictionary and convenience parameters.\n",
    "        if offset is not None and \"offset\" in payload:\n",
    "            raise ValueError(\n",
    "                \"offset is set in both payload and as a convenience parameter\"\n",
    "            )\n",
    "        if limit is not None and \"limit\" in payload:\n",
    "            raise ValueError(\n",
    "                \"limit is set in both payload and as a convenience parameter\"\n",
    "            )\n",
    "\n",
    "        if offset:\n",
    "            payload[\"offset\"] = offset\n",
    "        if limit:\n",
    "            payload[\"limit\"] = limit\n",
    "\n",
    "        # Rate limit handling: wait until 1 second has passed since the last request\n",
    "        if self.follow_rate_limit and self.last_request_timestamp:\n",
    "            time_since_last_request = (\n",
    "                datetime.datetime.utcnow() - self.last_request_timestamp\n",
    "            )\n",
    "            while time_since_last_request < timedelta(seconds=1):\n",
    "                time_since_last_request = (\n",
    "                    datetime.datetime.utcnow() - self.last_request_timestamp\n",
    "                )\n",
    "                pass\n",
    "\n",
    "        response = session.post(self.API_URL, json=payload)\n",
    "\n",
    "        # Response timestamping, with carveout for more rapid calls if previously cached\n",
    "        res_ts = datetime.datetime.utcnow()\n",
    "        if parameters[\"use_cache\"]:\n",
    "            if response.from_cache:\n",
    "                pass\n",
    "            else:\n",
    "                self.last_request_timestamp = res_ts\n",
    "        else:\n",
    "            self.last_request_timestamp = res_ts\n",
    "\n",
    "        if response.status_code != 200:\n",
    "            raise ValueError(\n",
    "                f\"API request failed with status code {response.status_code}. Error message: {response.text}\"\n",
    "            )\n",
    "\n",
    "        response_json = response.json()\n",
    "        if \"error\" in response_json:\n",
    "            raise ValueError(\n",
    "                f\"API request returned an error: {response_json['error']}.\"\n",
    "            )\n",
    "\n",
    "        return response_json\n",
    "\n",
    "    def get_projects_by_day(\n",
    "        self,\n",
    "        date: datetime.date,\n",
    "        datefield: str = \"date_added\",\n",
    "        add_timestamp_field: bool = False,\n",
    "        added_timestamp_field_name: str = \"_record_crawled_at\",\n",
    "        excessive_results_strategy=\"error\",\n",
    "        progress_bar: bool = False,\n",
    "    ) -> List[Dict[Any, Any]]:\n",
    "        \"\"\"\n",
    "        Retrieves projects added on a specific day.\n",
    "\n",
    "        Args:\n",
    "            date (datetime.date): The date to retrieve projects for.\n",
    "            datefield (str, optional): The date field to search on. Defaults to \"date_added\".\n",
    "            add_timestamp_field (bool): When true, will add a field to each record with the timestamp of the crawl. Field is named with `added_timestamp_field_name`\n",
    "            added_timestamp_field_name (str):  When add_timestamp_field == True, this is the name of the new field added to each project\n",
    "            excessive_results_strategy (str, optional): The strategy to use when the number of results exceeds the maximum. Defaults to 'error'. Options are 'error', 'warn', and 'ignore'. 'warn' and 'ignore' will retrieve up to 15000 results but will not be able to retrieve results beyond that limit.\n",
    "            progress_bar (bool, optional): Whether to display a progress bar. Defaults to False.\n",
    "\n",
    "        Returns:\n",
    "            List[Dict[Any, Any]]: The list of projects added on the specified day.\n",
    "        \"\"\"\n",
    "\n",
    "        projects = []\n",
    "        result_page_length = 500\n",
    "        max_results = 14999  # NIH RePORTER API constraint\n",
    "        sort_order = \"asc\"\n",
    "\n",
    "        payload = {\n",
    "            \"criteria\": {\n",
    "                datefield: {\n",
    "                    \"from_date\": date.strftime(\"%Y-%m-%d\"),\n",
    "                    \"to_date\": (date + timedelta(days=1)).strftime(\"%Y-%m-%d\"),\n",
    "                }\n",
    "            },\n",
    "            \"sort_field\": datefield,\n",
    "            \"sort_order\": sort_order,\n",
    "        }\n",
    "\n",
    "        # Get the metadata for the day's results\n",
    "        # Used for determining excessive results and optional tqdm progress bar\n",
    "        info_response = self.projects_search(payload, limit=1)\n",
    "        total_results = info_response[\"meta\"][\"total\"]\n",
    "\n",
    "        # Check for excessive results and handle according to selected strategy\n",
    "        # Example days for excessive results:\n",
    "        ## 2014-09-12: 18,160 results\n",
    "        if total_results > max_results:\n",
    "            if excessive_results_strategy == \"error\":\n",
    "                raise ValueError(\n",
    "                    f\"Number of results ({total_results}) exceeds the maximum ({max_results}) on {date}.\"\n",
    "                )\n",
    "            elif excessive_results_strategy == \"warn\":\n",
    "                warnings.warn(\n",
    "                    f\"Number of results ({total_results}) exceeds the maximum ({max_results}) on {date}.\"\n",
    "                )\n",
    "                # TODO: You are NOT elegantly failing when you hit the limit. Instead it just tries to exceed 15000 and fails.\n",
    "            elif excessive_results_strategy == \"ignore\":\n",
    "                pass\n",
    "            else:\n",
    "                raise ValueError(\n",
    "                    f\"Invalid excessive_results_strategy value: {excessive_results_strategy}.\"\n",
    "                )\n",
    "\n",
    "        if total_results > 0:\n",
    "            if progress_bar:\n",
    "                pbar = tqdm(\n",
    "                    total=total_results, desc=f\"Retrieving NIH projects for {date}\"\n",
    "                )\n",
    "\n",
    "            offset = 0\n",
    "            while len(projects) < total_results:\n",
    "                payload[\"offset\"] = offset\n",
    "                payload[\"limit\"] = result_page_length\n",
    "                response = self.projects_search(payload=payload)\n",
    "                response_ts = datetime.datetime.utcnow()\n",
    "                response_projects = response[\"results\"]\n",
    "\n",
    "                if add_timestamp_field:\n",
    "                    # use list comprehension\n",
    "                    response_projects = [\n",
    "                        {**project, added_timestamp_field_name: response_ts}\n",
    "                        for project in response_projects\n",
    "                    ]\n",
    "\n",
    "                n_results = len(response_projects)\n",
    "                projects.extend(response_projects)\n",
    "                offset += n_results\n",
    "                if progress_bar:\n",
    "                    pbar.update(n_results)\n",
    "\n",
    "            if progress_bar:\n",
    "                pbar.close()\n",
    "\n",
    "        if len(projects) != total_results:\n",
    "            raise ValueError(\n",
    "                f\"Number of projects retrieved ({len(projects)}) does not match the total number of projects ({total_results}) for {date}.\"\n",
    "            )\n",
    "\n",
    "        return projects\n",
    "\n",
    "    def count_projects_added_in_date_range(\n",
    "        self,\n",
    "        start_date: datetime.date,\n",
    "        end_date: datetime.date,\n",
    "    ) -> int:\n",
    "        \"\"\"\n",
    "        Counts the number of projects added in a date range.\n",
    "\n",
    "        Args:\n",
    "            start_date (datetime.date): The date to start counting projects for.\n",
    "            end_date (datetime.date): The date to stop counting projects for.\n",
    "\n",
    "        Returns:\n",
    "            int: The number of projects added in the specified date range.\n",
    "        \"\"\"\n",
    "\n",
    "        payload = {\n",
    "            \"criteria\": {\n",
    "                \"date_added\": {\n",
    "                    \"from_date\": start_date.strftime(\"%Y-%m-%d\"),\n",
    "                    \"to_date\": end_date.strftime(\"%Y-%m-%d\"),\n",
    "                }\n",
    "            },\n",
    "            \"sort_field\": \"date_added\",\n",
    "            \"sort_order\": \"asc\",\n",
    "        }\n",
    "\n",
    "        response = self.projects_search(payload, limit=1)\n",
    "        return response[\"meta\"][\"total\"]\n",
    "\n",
    "    def get_projects_added_in_date_range(\n",
    "        self,\n",
    "        start_date: datetime.date,\n",
    "        end_date: datetime.date,\n",
    "        progress_bar=False,\n",
    "        daily_progress_bar=False,\n",
    "    ) -> List[Dict[Any, Any]]:\n",
    "        \"\"\"\n",
    "        Retrieves projects added on a specific day.\n",
    "\n",
    "        Args:\n",
    "            start_date (datetime.date): The date to start retrieving projects for.\n",
    "            end_date (datetime.date): The date to stop retrieving projects for.\n",
    "            progress_bar (bool, optional): Whether to display a progress bar. Defaults to False.\n",
    "\n",
    "        Returns:\n",
    "            List[Dict[Any, Any]]: The list of projects added on the specified day.\n",
    "        \"\"\"\n",
    "\n",
    "        projects: List[Dict[Any, Any]] = []\n",
    "        total_projects = self.count_projects_added_in_date_range(start_date, end_date)\n",
    "        if progress_bar:\n",
    "            pbar = tqdm(\n",
    "                total=total_projects,\n",
    "                desc=f\"Retrieving Projects for {start_date} to {end_date}\",\n",
    "            )\n",
    "        date_spine = [\n",
    "            start_date + timedelta(days=x) for x in range((end_date - start_date).days)\n",
    "        ]\n",
    "        for date in date_spine:\n",
    "            projects_on_date = self.get_projects_by_day(\n",
    "                date,\n",
    "                add_timestamp_field=True,\n",
    "                progress_bar=daily_progress_bar,\n",
    "                excessive_results_strategy=\"warn\",\n",
    "            )\n",
    "            projects.extend(projects_on_date)\n",
    "            if progress_bar:\n",
    "                pbar.update(len(projects_on_date))\n",
    "        if progress_bar:\n",
    "            pbar.close()\n",
    "\n",
    "        if len(projects) != total_projects:\n",
    "            raise ValueError(\n",
    "                f\"Number of projects retrieved ({len(projects)}) does not match the total number of projects ({total_projects}) for the date range {start_date} to {end_date}.\"\n",
    "            )\n",
    "        return projects"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Strategies for dealing with too many records:\n",
    "When the number of records is too lage, the API will throw an error (get the error). It has a limit of 500 records per request and 15000 (via offset 14999) from a search, though it'll tell the absolute number of records.\n",
    "\n",
    "##### Strategy 1: < 30,000: Sort by ascending & descending. When results = full count stop. Check for uniqueness.\n",
    "\n",
    "##### Strategy 2: >= 30,000: Use another date field as a secondary filter.\n",
    "\n",
    "If the count is greater than 15,000, include an additional date field (e.g. `project_start_date`) as part of the filtering criteria, in addition to `date_added`.  Get the minimum and maximum values for the date field by making 2 API requests of limit=1, sort ascending and descending.\n",
    "\n",
    "Begin pulling all records for each year (starting with min_date -> JAN1 of next year) by returning results with limit=500. If a set of results > 15,000 for the year, discard the first result set and subdivide the year into months and pull from MONTH, 1 to MONTH+1, 1. Subdivide to days if > 14,999 for a month.\n",
    "\n",
    "For the last results, we'll want to make sure we can project into the furute ans so would want to start only with a from_date and not a to_date. However if that's also over 15,000, we'll need a way to forward project.\n",
    "\n",
    "Be sure to test this using the date_added results > 15,000 days (as discovered below)\n",
    "\n",
    "TODO validate that we can filter `{ \"criteria\": {\"award_notice_date\":{ \"from_date\":\"2021-02-17\", \"to_date\":\"2022-02-17\" } }}` on only one of these criteria (e.g. a min date but not a max / visa versa)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Additional NIH Data\n",
    "We need to get the data for the NIH's agencies IDs to correspond to their ROR ID's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "FUNDER_NAME = \"National Institutes of Health\"\n",
    "FUNDER_ROR_ID = \"https://ror.org/01cwqze88\"\n",
    "NIH_IC_AGENCY = [\n",
    "    {\n",
    "        \"acronym\": \"CC\",\n",
    "        \"full_name\": \"Clinical Center\",\n",
    "        \"org_code\": \"CC\",\n",
    "        \"payload_criteria_value\": \"CLC\",\n",
    "        \"ror_id\": \"https://ror.org/04vfsmv21\",\n",
    "    },\n",
    "    {\n",
    "        \"acronym\": \"CSR\",\n",
    "        \"full_name\": \"Center for Scientific Review\",\n",
    "        \"org_code\": \"RG\",\n",
    "        \"payload_criteria_value\": \"CSR\",\n",
    "        \"ror_id\": \"https://ror.org/04r5s4b52\",\n",
    "    },\n",
    "    {\n",
    "        \"acronym\": \"CIT\",\n",
    "        \"full_name\": \"Center for Information Technology\",\n",
    "        \"org_code\": \"CIT\",\n",
    "        \"payload_criteria_value\": \"CIT\",\n",
    "        \"ror_id\": \"https://ror.org/03jh5a977\",\n",
    "    },\n",
    "    {\n",
    "        \"acronym\": \"FIC\",\n",
    "        \"full_name\": \"John E. Fogarty International Center\",\n",
    "        \"org_code\": \"TW\",\n",
    "        \"payload_criteria_value\": \"FIC\",\n",
    "        \"ror_id\": \"https://ror.org/02xey9a22\",\n",
    "    },\n",
    "    {\n",
    "        \"acronym\": \"NCATS\",\n",
    "        \"full_name\": \"National Center for Advancing Translational Sciences (NCATS)\",\n",
    "        \"org_code\": \"TR\",\n",
    "        \"payload_criteria_value\": \"NCATS\",\n",
    "        \"ror_id\": \"https://ror.org/04pw6fb54\",\n",
    "    },\n",
    "    {\n",
    "        \"acronym\": \"NCCIH\",\n",
    "        \"full_name\": \"National Center for Complementary and Integrative Health\",\n",
    "        \"org_code\": \"AT\",\n",
    "        \"payload_criteria_value\": \"NCCIH\",\n",
    "        \"ror_id\": \"https://ror.org/00190t495\",\n",
    "    },\n",
    "    {\n",
    "        \"acronym\": \"NCI\",\n",
    "        \"full_name\": \"National Cancer Institute\",\n",
    "        \"org_code\": \"CA\",\n",
    "        \"payload_criteria_value\": \"NCI\",\n",
    "        \"ror_id\": \"https://ror.org/040gcmg81\",\n",
    "    },\n",
    "    {\n",
    "        \"acronym\": \"NCRR\",\n",
    "        \"full_name\": \"National Center for Research Resources (dissolved 12/2011)\",\n",
    "        \"org_code\": \"RR\",\n",
    "        \"payload_criteria_value\": \"NCRR\",\n",
    "        \"ror_id\": \"https://ror.org/01cwqze88\",\n",
    "    },\n",
    "    {\n",
    "        \"acronym\": \"NEI\",\n",
    "        \"full_name\": \"National Eye Institute\",\n",
    "        \"org_code\": \"EY\",\n",
    "        \"payload_criteria_value\": \"NEI\",\n",
    "        \"ror_id\": \"https://ror.org/03wkg3b53\",\n",
    "    },\n",
    "    {\n",
    "        \"acronym\": \"NHGRI\",\n",
    "        \"full_name\": \"National Human Genome Research Institute\",\n",
    "        \"org_code\": \"HG\",\n",
    "        \"payload_criteria_value\": \"NHGRI\",\n",
    "        \"ror_id\": \"https://ror.org/00baak391\",\n",
    "    },\n",
    "    {\n",
    "        \"acronym\": \"NHLBI\",\n",
    "        \"full_name\": \"National Heart, Lung, and Blood Institute\",\n",
    "        \"org_code\": \"HL\",\n",
    "        \"payload_criteria_value\": \"NHLBI\",\n",
    "        \"ror_id\": \"https://ror.org/012pb6c26\",\n",
    "    },\n",
    "    {\n",
    "        \"acronym\": \"NIA\",\n",
    "        \"full_name\": \"National Institute on Aging\",\n",
    "        \"org_code\": \"AG\",\n",
    "        \"payload_criteria_value\": \"NIA\",\n",
    "        \"ror_id\": \"https://ror.org/049v75w11\",\n",
    "    },\n",
    "    {\n",
    "        \"acronym\": \"NIAAA\",\n",
    "        \"full_name\": \"National Institute on Alcohol Abuse and Alcoholism\",\n",
    "        \"org_code\": \"AA\",\n",
    "        \"payload_criteria_value\": \"NIAAA\",\n",
    "        \"ror_id\": \"https://ror.org/02jzrsm59\",\n",
    "    },\n",
    "    {\n",
    "        \"acronym\": \"NIAID\",\n",
    "        \"full_name\": \"National Institute of Allergy and Infectious Diseases\",\n",
    "        \"org_code\": \"AI\",\n",
    "        \"payload_criteria_value\": \"NIAID\",\n",
    "        \"ror_id\": \"https://ror.org/043z4tv69\",\n",
    "    },\n",
    "    {\n",
    "        \"acronym\": \"NIAMS\",\n",
    "        \"full_name\": \"National Institute of Arthritis and Musculoskeletal and Skin Diseases\",\n",
    "        \"org_code\": \"AR\",\n",
    "        \"payload_criteria_value\": \"NIAMS\",\n",
    "        \"ror_id\": \"https://ror.org/006zn3t30\",\n",
    "    },\n",
    "    {\n",
    "        \"acronym\": \"NIBIB\",\n",
    "        \"full_name\": \"National Institute of Biomedical Imaging and Bioengineering\",\n",
    "        \"org_code\": \"EB\",\n",
    "        \"payload_criteria_value\": \"NIBIB\",\n",
    "        \"ror_id\": \"https://ror.org/00372qc85\",\n",
    "    },\n",
    "    {\n",
    "        \"acronym\": \"NICHD\",\n",
    "        \"full_name\": \"Eunice Kennedy Shriver National Institute of Child Health and Human Development\",\n",
    "        \"org_code\": \"HD\",\n",
    "        \"payload_criteria_value\": \"NICHD\",\n",
    "        \"ror_id\": \"https://ror.org/04byxyr05\",\n",
    "    },\n",
    "    {\n",
    "        \"acronym\": \"NIDA\",\n",
    "        \"full_name\": \"National Institute on Drug Abuse\",\n",
    "        \"org_code\": \"DA\",\n",
    "        \"payload_criteria_value\": \"NIDA\",\n",
    "        \"ror_id\": \"https://ror.org/00fq5cm18\",\n",
    "    },\n",
    "    {\n",
    "        \"acronym\": \"NIDCD\",\n",
    "        \"full_name\": \"National Institute on Deafness and Other Communication Disorders\",\n",
    "        \"org_code\": \"DC\",\n",
    "        \"payload_criteria_value\": \"NIDCD\",\n",
    "        \"ror_id\": \"https://ror.org/04mhx6838\",\n",
    "    },\n",
    "    {\n",
    "        \"acronym\": \"NIDCR\",\n",
    "        \"full_name\": \"National Institute of Dental and Craniofacial Research\",\n",
    "        \"org_code\": \"DE\",\n",
    "        \"payload_criteria_value\": \"NIDCR\",\n",
    "        \"ror_id\": \"https://ror.org/004a2wv92\",\n",
    "    },\n",
    "    {\n",
    "        \"acronym\": \"NIDDK\",\n",
    "        \"full_name\": \"National Institute of Diabetes and Digestive and Kidney Diseases\",\n",
    "        \"org_code\": \"DK\",\n",
    "        \"payload_criteria_value\": \"NIDDK\",\n",
    "        \"ror_id\": \"https://ror.org/00adh9b73\",\n",
    "    },\n",
    "    {\n",
    "        \"acronym\": \"NIEHS\",\n",
    "        \"full_name\": \"National Institute of Environmental Health Sciences\",\n",
    "        \"org_code\": \"ES\",\n",
    "        \"payload_criteria_value\": \"NIEHS\",\n",
    "        \"ror_id\": \"https://ror.org/00j4k1h63\",\n",
    "    },\n",
    "    {\n",
    "        \"acronym\": \"NIGMS\",\n",
    "        \"full_name\": \"National Institute of General Medical Sciences\",\n",
    "        \"org_code\": \"GM\",\n",
    "        \"payload_criteria_value\": \"NIGMS\",\n",
    "        \"ror_id\": \"https://ror.org/04q48ey07\",\n",
    "    },\n",
    "    {\n",
    "        \"acronym\": \"NIMH\",\n",
    "        \"full_name\": \"National Institute of Mental Health\",\n",
    "        \"org_code\": \"MH\",\n",
    "        \"payload_criteria_value\": \"NIMH\",\n",
    "        \"ror_id\": \"https://ror.org/04xeg9z08\",\n",
    "    },\n",
    "    {\n",
    "        \"acronym\": \"NIMHD\",\n",
    "        \"full_name\": \"National Institute on Minority Health and Health Disparities\",\n",
    "        \"org_code\": \"MD\",\n",
    "        \"payload_criteria_value\": \"NIMHD\",\n",
    "        \"ror_id\": \"https://ror.org/0493hgw16\",\n",
    "    },\n",
    "    {\n",
    "        \"acronym\": \"NINDS\",\n",
    "        \"full_name\": \"National Institute of Neurological Disorders and Stroke\",\n",
    "        \"org_code\": \"NS\",\n",
    "        \"payload_criteria_value\": \"NINDS\",\n",
    "        \"ror_id\": \"https://ror.org/01s5ya894\",\n",
    "    },\n",
    "    {\n",
    "        \"acronym\": \"NINR\",\n",
    "        \"full_name\": \"National Institute of Nursing Research\",\n",
    "        \"org_code\": \"NR\",\n",
    "        \"payload_criteria_value\": \"NINR\",\n",
    "        \"ror_id\": \"https://ror.org/01y3zfr79\",\n",
    "    },\n",
    "    {\n",
    "        \"acronym\": \"NLM\",\n",
    "        \"full_name\": \"National Library of Medicine\",\n",
    "        \"org_code\": \"LM\",\n",
    "        \"payload_criteria_value\": \"NLM\",\n",
    "        \"ror_id\": \"https://ror.org/0060t0j89\",\n",
    "    },\n",
    "    {\n",
    "        \"acronym\": \"OD\",\n",
    "        \"full_name\": \"Office of the Director\",\n",
    "        \"org_code\": \"OD\",\n",
    "        \"payload_criteria_value\": \"OD\",\n",
    "        \"ror_id\": \"https://ror.org/00fj8a872\",\n",
    "    },\n",
    "]\n",
    "\n",
    "lookup_agency = {agency[\"org_code\"]: agency for agency in NIH_IC_AGENCY}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### NIH API Analysis:\n",
    "\n",
    "Determine the number of records we're crawling on a daily basis. We can embed this as a graphic, but mostly this is just useful analysis to understand if we need more advanced crawling techniques."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def count_projects_by_date(\n",
    "#     start_date: datetime.date, end_date: datetime.date\n",
    "# ) -> Dict[datetime.date, int]:\n",
    "#     nih = NihApi()\n",
    "\n",
    "#     # count the number of projects added for each date from START_DATE to END_DATE\n",
    "\n",
    "#     date_spine = [\n",
    "#         parameters[\"start_date\"] + timedelta(days=x)\n",
    "#         for x in range((parameters[\"end_date\"] - parameters[\"start_date\"]).days)\n",
    "#     ]\n",
    "\n",
    "#     # records_added_daily_count = {date: nih.count_projects_added_in_date_range(date, date + timedelta(days=1)) for date in date_spine}\n",
    "\n",
    "#     records_added_daily_count = {}\n",
    "#     for date in tqdm(date_spine, total=len(date_spine)):\n",
    "#         try:\n",
    "#             today_count = nih.count_projects_added_in_date_range(\n",
    "#                 date, date + timedelta(days=1)\n",
    "#             )\n",
    "#             records_added_daily_count[date] = today_count\n",
    "#             if today_count > 14999:\n",
    "#                 print(f\"Warning: {today_count} records added on {date}.\")\n",
    "#         except ValueError as e:\n",
    "#             print(f\"Error: {e}\")\n",
    "#             records_added_daily_count[date] = 0\n",
    "#     return records_added_daily_count\n",
    "\n",
    "\n",
    "# # records_added_daily_count = count_projects_by_date(parameters['start_date'], parameters['end_date'])\n",
    "# # count_daily_records = pd.DataFrame(records_added_daily_count.items(), columns=[\"date\", \"count\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get and Clean Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nih = NihApi()\n",
    "# projects = nih.get_projects_added_in_date_range(\n",
    "#     parameters[\"start_date\"],\n",
    "#     parameters[\"end_date\"],\n",
    "#     progress_bar=True,\n",
    "#     daily_progress_bar=True,\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# projects_df = pd.json_normalize(projects, max_level=2)\n",
    "# del projects"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set types for columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# date_columns = [\n",
    "#     \"project_start_date\",\n",
    "#     \"project_end_date\",\n",
    "#     \"award_notice_date\",\n",
    "#     \"budget_start\",\n",
    "#     \"budget_end\",\n",
    "#     \"date_added\",\n",
    "# ]\n",
    "\n",
    "# for col in date_columns:\n",
    "#     projects_df[col] = pd.to_datetime(projects_df[col])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Cleaning Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_ror_id(code):\n",
    "#     \"\"\"\n",
    "#     Retrieves the ROR ID associated with the given NIH agency code.\n",
    "\n",
    "#     Args:\n",
    "#         code (str): The code to look up.\n",
    "\n",
    "#     Returns:\n",
    "#         str or None: The ROR ID if found, None otherwise.\n",
    "#     \"\"\"\n",
    "#     return lookup_agency[code][\"ror_id\"] if code in lookup_agency else None\n",
    "\n",
    "\n",
    "# ## delete if we do away with Pandas\n",
    "# def build_location(row):\n",
    "#     \"\"\"\n",
    "#     Builds a location string based on the provided row data.\n",
    "\n",
    "#     Args:\n",
    "#         row (pandas.Series): The row containing organization information.\n",
    "\n",
    "#     Returns:\n",
    "#         str: The location string.\n",
    "#     \"\"\"\n",
    "#     location = \"\"\n",
    "#     if pd.notnull(row[\"organization.org_city\"]):\n",
    "#         location += f\"{row['organization.org_city']}, \"\n",
    "#     elif pd.notnull(row[\"organization.city\"]):\n",
    "#         location += f\"{row['organization.city']}, \"\n",
    "#     if pd.notnull(row[\"organization.org_zipcode\"]):\n",
    "#         # handle zip-5/zip-9 formats\n",
    "#         if row[\"organization.org_zipcode\"].isnumeric():\n",
    "#             if len(row[\"organization.org_zipcode\"]) == 5:\n",
    "#                 location += f\"{row['organization.org_zipcode']} ,\"\n",
    "#             elif len(row[\"organization.org_zipcode\"]) == 9:\n",
    "#                 location += f\"{row['organization.org_zipcode'][:5]}-{row['organization.org_zipcode'][5:]}, \"\n",
    "#         else:\n",
    "#             location += f\"{row['organization.org_zipcode']}, \"\n",
    "#     if pd.notnull(row[\"organization.org_country\"]):\n",
    "#         location += row[\"organization.org_country\"]\n",
    "#     elif pd.notnull(row[\"organization.country\"]):\n",
    "#         location += row[\"organization.country\"]\n",
    "#     return location\n",
    "\n",
    "\n",
    "# def extract_format_pi_names(pi_list) -> str:\n",
    "#     return \" | \".join(pi[\"full_name\"] for pi in pi_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Format data for export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export_df = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export_df[\"grant_id\"] = \"nih::\" + projects_df[\"appl_id\"].astype(str)\n",
    "# export_df[\"funder_name\"] = \"National Institutes of Health: \" + projects_df[\n",
    "#     \"agency_ic_admin.name\"\n",
    "# ].astype(str)\n",
    "# export_df[\"funder_ror_id\"] = projects_df[\"agency_ic_admin.code\"].apply(get_ror_id)\n",
    "# export_df[\"recipient_org_name\"] = projects_df[\"organization.org_name\"]\n",
    "# export_df[\"recipient_location\"] = projects_df.apply(build_location, axis=1)\n",
    "\n",
    "# export_df[\"grant_year\"] = projects_df[\"budget_start\"].dt.year\n",
    "# export_df[\"grant_duration\"] = (\n",
    "#     projects_df[\"budget_end\"].dt.date - projects_df[\"budget_start\"].dt.date\n",
    "# )\n",
    "# export_df[\"grant_start_date\"] = projects_df[\"budget_start\"].dt.date\n",
    "# export_df[\"grant_end_date\"] = projects_df[\"budget_end\"].dt.date\n",
    "\n",
    "# export_df[\"award_amount\"] = projects_df[\"award_amount\"]\n",
    "# export_df[\"award_currency\"] = \"USD\"\n",
    "# export_df[\"award_amount_usd\"] = projects_df[\"award_amount\"]\n",
    "# export_df[\"source\"] = \"NIH RePORTER API\"\n",
    "# export_df[\"source_url\"] = \"https://api.reporter.nih.gov/?urls.primaryName=V2.0\"\n",
    "# export_df[\"grant_title\"] = projects_df[\"project_title\"]\n",
    "# export_df[\"grant_description\"] = (\n",
    "#     \"PROJECT TITLE: \"\n",
    "#     + projects_df[\"project_title\"]\n",
    "#     + \"\\n\\n\\n PROJECT ABSTRACT:\\n\"\n",
    "#     + projects_df[\"abstract_text\"]\n",
    "#     + \"\\n\\n\\n\"\n",
    "#     + \"PUBLIC HEALTH RELEVANCE STATEMENT: \\n\"\n",
    "#     + projects_df[\"phr_text\"]\n",
    "# )\n",
    "# export_df[\"grant_category\"] = projects_df[\"funding_mechanism\"]\n",
    "\n",
    "# ## Notify the user if the record represents a subproject\n",
    "# subproject_comment = \"Grant record is for a subproject. Value reflected here is value of the subproject only. Parent grant has cumulative value of funding of all subprojects. If summed, this value may be counted twice if using the overall dataset. Use the project_id in the NIH's raw_source_data if you would like to identify the parent project.\"\n",
    "\n",
    "# export_df[\"comment\"] = projects_df[\"subproject_id\"].where(\n",
    "#     projects_df[\"subproject_id\"].isna(), subproject_comment\n",
    "# )\n",
    "\n",
    "# export_df[\"_crawled_at\"] = projects_df[\"_record_crawled_at\"]\n",
    "# export_df[\"raw_export_data\"] = projects_df.drop(\"_record_crawled_at\", axis=1).to_dict(\n",
    "#     orient=\"records\"\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# del projects_df\n",
    "# export_df.to_json(OUTPUT_LOCATION, orient=\"records\", lines=True, date_format=\"iso\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Split the file so it will fit\n",
    "# ! split -C 95M --numeric-suffixes --additional-suffix .jsonl {OUTPUT_LOCATION} {OUTPUT_LOCATION.split('.jsonl')[0]}_part_\n",
    "\n",
    "# # Remove the original file so oversize file doesn't get committed\n",
    "# ! rm {OUTPUT_LOCATION}\n",
    "\n",
    "# ! ls {OUTPUT_LOCATION.split('.jsonl')[0]}*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process Data on a Daily Basis; use out-of-memory processing\n",
    "\n",
    "We've run into memory issues while doing this all in Pandas. Instead, we will:\n",
    "1. do the data transformation on each record as we get it (daily)\n",
    "2. Put each record into AwardItem objects\n",
    "3. Turn a whole day's AwardItems into a Polars dataframe\n",
    "4. Write that Polars dataframe to an on-disk DuckDB database\n",
    "5. Allow the Garbage Collector to free the dict and the Dataframe (or do it ourselves)\n",
    "6. Once complete, we can have DuckDB export the records to a JSON file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleaning for building the AwardItem\n",
    "\n",
    "\n",
    "def build_clean_location(project: dict[Any, Any]) -> str:\n",
    "    \"\"\"\n",
    "    Builds a location string based on the project's various location fields data.\n",
    "\n",
    "    Args:\n",
    "        project: one NIH Project entity from the NihAPI.\n",
    "\n",
    "    Returns:\n",
    "        str: The formatted location string.\n",
    "    \"\"\"\n",
    "    location = \"\"\n",
    "    organization = project.get(\"organization\", {})\n",
    "    if organization.get(\"org_city\"):\n",
    "        location += f\"{organization['org_city']}, \"\n",
    "    elif organization.get(\"city\"):\n",
    "        location += f\"{organization['city']}, \"\n",
    "    if organization.get(\"org_state\"):\n",
    "        location += f\"{organization['org_state']}, \"\n",
    "    if organization.get(\"org_zipcode\"):\n",
    "        # handle zip-5/zip-9 formats\n",
    "        zipcode = organization[\"org_zipcode\"]\n",
    "        if zipcode.isnumeric():\n",
    "            if len(zipcode) == 5:\n",
    "                location += f\"{zipcode} ,\"\n",
    "            elif len(zipcode) == 9:\n",
    "                location += f\"{zipcode[:5]}-{zipcode[5:]}, \"\n",
    "        else:\n",
    "            location += f\"{zipcode}, \"\n",
    "    if organization.get(\"org_country\"):\n",
    "        location += organization[\"org_country\"]\n",
    "    elif organization.get(\"country\"):\n",
    "        location += organization[\"country\"]\n",
    "    return location\n",
    "\n",
    "\n",
    "def get_ror_id(code):\n",
    "    \"\"\"\n",
    "    Retrieves the ROR ID associated with the given NIH agency code.\n",
    "\n",
    "    Args:\n",
    "        code (str): The code to look up.\n",
    "\n",
    "    Returns:\n",
    "        str or None: The ROR ID if found, None otherwise.\n",
    "    \"\"\"\n",
    "    return lookup_agency[code][\"ror_id\"] if code in lookup_agency else None\n",
    "\n",
    "\n",
    "subproject_comment = \"Grant record is for a subproject. Value reflected here is value of the subproject only. Parent grant has cumulative value of funding of all subprojects. If summed, this value may be counted twice if using the overall dataset. Use the project_id in the NIH's raw_source_data if you would like to identify the parent project.\"\n",
    "\n",
    "\n",
    "def structure_award_item(project: dict[Any, Any]) -> AwardItem:\n",
    "    \"\"\"\n",
    "    Structures the AwardItem from the NIH project data.\n",
    "\n",
    "    Args:\n",
    "        project: one NIH Project entity from the NihAPI.\n",
    "\n",
    "    Returns:\n",
    "        AwardItem: The structured AwardItem.\n",
    "    \"\"\"\n",
    "\n",
    "    # Build the most complex thing: the PI List:\n",
    "    pi_list = []\n",
    "    for pi in project[\"principal_investigators\"]:\n",
    "        pi_list.append(\n",
    "            AwardParticipant(\n",
    "                full_name=\" \".join(\n",
    "                    name\n",
    "                    for name in (pi[\"first_name\"], pi[\"middle_name\"], pi[\"last_name\"])\n",
    "                    if name\n",
    "                ),\n",
    "                is_pi=pi[\"is_contact_pi\"],\n",
    "                grant_role=\"Contact PI\" if pi[\"is_contact_pi\"] else \"PI\",\n",
    "                first_name=pi[\"first_name\"],\n",
    "                middle_name=pi[\"middle_name\"],\n",
    "                last_name=pi[\"last_name\"],\n",
    "                identifiers={\"nih_profile_id\": str(pi[\"profile_id\"])},\n",
    "            )\n",
    "        )\n",
    "\n",
    "    # Build the components of the AwardItem\n",
    "    crawled_at = project[\"_record_crawled_at\"]\n",
    "    del project[\"_record_crawled_at\"]  # remove added field for export\n",
    "\n",
    "    source_data = str(project)\n",
    "    grant_start_date = (\n",
    "        dateutil.parser.parse(project[\"budget_start\"])\n",
    "        if project.get(\"budget_start\")\n",
    "        else None\n",
    "    )\n",
    "    grant_end_date = (\n",
    "        dateutil.parser.parse(project[\"budget_end\"])\n",
    "        if project.get(\"budget_end\")\n",
    "        else None\n",
    "    )\n",
    "\n",
    "    ai = AwardItem(\n",
    "        _crawled_at=crawled_at,\n",
    "        source=\"nih.gov\",\n",
    "        grant_id=f\"nih::{project['appl_id']}\",\n",
    "        funder_org_name=f\"National Institutes of Health: {project['agency_ic_admin']['name']}\"\n",
    "        if project.get(\"agency_ic_admin\")\n",
    "        else \"National Institutes of Health\",\n",
    "        funder_org_ror_id=get_ror_id(project[\"agency_ic_admin\"][\"code\"])\n",
    "        if project[\"agency_ic_admin\"]\n",
    "        else FUNDER_ROR_ID,\n",
    "        recipient_org_name=project[\"organization\"][\"org_name\"]\n",
    "        if project[\"organization\"].get(\"org_name\")\n",
    "        else \"__Organization Unknown__\",\n",
    "        recipient_org_location=build_clean_location(project),\n",
    "        pi_name=next(\n",
    "            (\n",
    "                person.full_name\n",
    "                for person in pi_list\n",
    "                if person.grant_role == \"Contact PI\"\n",
    "            ),\n",
    "            None,\n",
    "        ),\n",
    "        named_participants=pi_list,\n",
    "        grant_start_date=grant_start_date,\n",
    "        grant_end_date=grant_end_date,\n",
    "        grant_year=grant_start_date.year if grant_start_date else None,\n",
    "        grant_duration=str(grant_end_date - grant_start_date)\n",
    "        if grant_start_date and grant_end_date\n",
    "        else None,\n",
    "        award_amount=float(project[\"award_amount\"])\n",
    "        if project.get(\"award_amount\")\n",
    "        else None,\n",
    "        award_currency=\"USD\",\n",
    "        award_amount_usd=float(project[\"award_amount\"])\n",
    "        if project.get(\"award_amount\")\n",
    "        else None,\n",
    "        source_url=project[\"project_detail_url\"],\n",
    "        grant_title=project[\"project_title\"],\n",
    "        grant_description=f\"PROJECT TITLE: {project['project_title']}\\n\\nPROJECT ABSTRACT:\\n{project['abstract_text']}\\n\\nPUBLIC HEALTH RELEVANCE STATEMENT: \\n{project['phr_text']}\",\n",
    "        program_of_funder=project[\"funding_mechanism\"],\n",
    "        comments=subproject_comment if project.get(\"subproject_id\") else None,\n",
    "        raw_source_data=source_data,\n",
    "        _award_schema_version=\"0.1.0\",\n",
    "    )\n",
    "    return ai"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Runing the process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "52eb5e082db346478a596b096544734e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Projects from 2022-10-01 to 2023-10-01:   0%|          | 0/86606 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieving projects for 2022-10-01\n",
      "Retrieving projects for 2022-10-02\n",
      "Retrieving projects for 2022-10-03\n",
      "Retrieving projects for 2022-10-04\n",
      "Retrieving projects for 2022-10-05\n",
      "Retrieving projects for 2022-10-06\n",
      "Retrieving projects for 2022-10-07\n",
      "Retrieving projects for 2022-10-08\n"
     ]
    },
    {
     "ename": "ComputeError",
     "evalue": "could not append value: \"Grant record is for a subproject. Value reflected here is value of the subproject only. Parent grant has cumulative value of funding of all subprojects. If summed, this value may be counted twice if using the overall dataset. Use the project_id in the NIH's raw_source_data if you would like to identify the parent project.\" of type: str to the builder; make sure that all rows have the same schema or consider increasing `infer_schema_length`\n\nit might also be that a value overflows the data-type's capacity",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mComputeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 34\u001b[0m\n\u001b[1;32m     31\u001b[0m         result_frame \u001b[38;5;241m=\u001b[39m pl\u001b[38;5;241m.\u001b[39mLazyFrame(futuredf)\n\u001b[1;32m     32\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     33\u001b[0m         result_frame \u001b[38;5;241m=\u001b[39m pl\u001b[38;5;241m.\u001b[39mconcat(\n\u001b[0;32m---> 34\u001b[0m             items\u001b[38;5;241m=\u001b[39m[result_frame, \u001b[43mpl\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mLazyFrame\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfuturedf\u001b[49m\u001b[43m)\u001b[49m], how\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvertical_relaxed\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     35\u001b[0m         )\n\u001b[1;32m     36\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:  \u001b[38;5;66;03m# no projects for this day\u001b[39;00m\n\u001b[1;32m     37\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/oic-scrape-D2fotO-x-py3.11/lib/python3.11/site-packages/polars/lazyframe/frame.py:303\u001b[0m, in \u001b[0;36mLazyFrame.__init__\u001b[0;34m(self, data, schema, schema_overrides, orient, infer_schema_length, nan_to_null)\u001b[0m\n\u001b[1;32m    290\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\n\u001b[1;32m    291\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    292\u001b[0m     data: FrameInitTypes \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    298\u001b[0m     nan_to_null: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    299\u001b[0m ):\n\u001b[1;32m    300\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpolars\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdataframe\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DataFrame\n\u001b[1;32m    302\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ldf \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m--> 303\u001b[0m         \u001b[43mDataFrame\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    304\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    305\u001b[0m \u001b[43m            \u001b[49m\u001b[43mschema\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mschema\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    306\u001b[0m \u001b[43m            \u001b[49m\u001b[43mschema_overrides\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mschema_overrides\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    307\u001b[0m \u001b[43m            \u001b[49m\u001b[43morient\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morient\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    308\u001b[0m \u001b[43m            \u001b[49m\u001b[43minfer_schema_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minfer_schema_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    309\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnan_to_null\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnan_to_null\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    310\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    311\u001b[0m         \u001b[38;5;241m.\u001b[39mlazy()\n\u001b[1;32m    312\u001b[0m         \u001b[38;5;241m.\u001b[39m_ldf\n\u001b[1;32m    313\u001b[0m     )\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/oic-scrape-D2fotO-x-py3.11/lib/python3.11/site-packages/polars/dataframe/frame.py:375\u001b[0m, in \u001b[0;36mDataFrame.__init__\u001b[0;34m(self, data, schema, schema_overrides, orient, infer_schema_length, nan_to_null)\u001b[0m\n\u001b[1;32m    367\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_df \u001b[38;5;241m=\u001b[39m dict_to_pydf(\n\u001b[1;32m    368\u001b[0m         data,\n\u001b[1;32m    369\u001b[0m         schema\u001b[38;5;241m=\u001b[39mschema,\n\u001b[1;32m    370\u001b[0m         schema_overrides\u001b[38;5;241m=\u001b[39mschema_overrides,\n\u001b[1;32m    371\u001b[0m         nan_to_null\u001b[38;5;241m=\u001b[39mnan_to_null,\n\u001b[1;32m    372\u001b[0m     )\n\u001b[1;32m    374\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, (\u001b[38;5;28mlist\u001b[39m, \u001b[38;5;28mtuple\u001b[39m, Sequence)):\n\u001b[0;32m--> 375\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_df \u001b[38;5;241m=\u001b[39m \u001b[43msequence_to_pydf\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    376\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    377\u001b[0m \u001b[43m        \u001b[49m\u001b[43mschema\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mschema\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    378\u001b[0m \u001b[43m        \u001b[49m\u001b[43mschema_overrides\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mschema_overrides\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    379\u001b[0m \u001b[43m        \u001b[49m\u001b[43morient\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morient\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    380\u001b[0m \u001b[43m        \u001b[49m\u001b[43minfer_schema_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minfer_schema_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    381\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    383\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, pl\u001b[38;5;241m.\u001b[39mSeries):\n\u001b[1;32m    384\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_df \u001b[38;5;241m=\u001b[39m series_to_pydf(\n\u001b[1;32m    385\u001b[0m         data, schema\u001b[38;5;241m=\u001b[39mschema, schema_overrides\u001b[38;5;241m=\u001b[39mschema_overrides\n\u001b[1;32m    386\u001b[0m     )\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/oic-scrape-D2fotO-x-py3.11/lib/python3.11/site-packages/polars/utils/_construction.py:1000\u001b[0m, in \u001b[0;36msequence_to_pydf\u001b[0;34m(data, schema, schema_overrides, orient, infer_schema_length)\u001b[0m\n\u001b[1;32m    997\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(data) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    998\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m dict_to_pydf({}, schema\u001b[38;5;241m=\u001b[39mschema, schema_overrides\u001b[38;5;241m=\u001b[39mschema_overrides)\n\u001b[0;32m-> 1000\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_sequence_to_pydf_dispatcher\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1001\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1002\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1003\u001b[0m \u001b[43m    \u001b[49m\u001b[43mschema\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mschema\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1004\u001b[0m \u001b[43m    \u001b[49m\u001b[43mschema_overrides\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mschema_overrides\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1005\u001b[0m \u001b[43m    \u001b[49m\u001b[43morient\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morient\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1006\u001b[0m \u001b[43m    \u001b[49m\u001b[43minfer_schema_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minfer_schema_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1007\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/lib/python3.11/functools.py:909\u001b[0m, in \u001b[0;36msingledispatch.<locals>.wrapper\u001b[0;34m(*args, **kw)\u001b[0m\n\u001b[1;32m    905\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m args:\n\u001b[1;32m    906\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfuncname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m requires at least \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    907\u001b[0m                     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m1 positional argument\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m--> 909\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdispatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;18;43m__class__\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/oic-scrape-D2fotO-x-py3.11/lib/python3.11/site-packages/polars/utils/_construction.py:1221\u001b[0m, in \u001b[0;36m_sequence_of_dict_to_pydf\u001b[0;34m(first_element, data, schema, schema_overrides, infer_schema_length, **kwargs)\u001b[0m\n\u001b[1;32m   1213\u001b[0m column_names, schema_overrides \u001b[38;5;241m=\u001b[39m _unpack_schema(\n\u001b[1;32m   1214\u001b[0m     schema, schema_overrides\u001b[38;5;241m=\u001b[39mschema_overrides\n\u001b[1;32m   1215\u001b[0m )\n\u001b[1;32m   1216\u001b[0m dicts_schema \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m   1217\u001b[0m     include_unknowns(schema_overrides, column_names \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(schema_overrides))\n\u001b[1;32m   1218\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m column_names\n\u001b[1;32m   1219\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1220\u001b[0m )\n\u001b[0;32m-> 1221\u001b[0m pydf \u001b[38;5;241m=\u001b[39m \u001b[43mPyDataFrame\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_dicts\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1222\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minfer_schema_length\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdicts_schema\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mschema_overrides\u001b[49m\n\u001b[1;32m   1223\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1225\u001b[0m \u001b[38;5;66;03m# TODO: we can remove this `schema_overrides` block completely\u001b[39;00m\n\u001b[1;32m   1226\u001b[0m \u001b[38;5;66;03m#  once https://github.com/pola-rs/polars/issues/11044 is fixed\u001b[39;00m\n\u001b[1;32m   1227\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m schema_overrides:\n",
      "\u001b[0;31mComputeError\u001b[0m: could not append value: \"Grant record is for a subproject. Value reflected here is value of the subproject only. Parent grant has cumulative value of funding of all subprojects. If summed, this value may be counted twice if using the overall dataset. Use the project_id in the NIH's raw_source_data if you would like to identify the parent project.\" of type: str to the builder; make sure that all rows have the same schema or consider increasing `infer_schema_length`\n\nit might also be that a value overflows the data-type's capacity"
     ]
    }
   ],
   "source": [
    "nih = NihApi()\n",
    "\n",
    "result_frame: Optional[pl.LazyFrame] = None\n",
    "\n",
    "start_date = datetime.date(2022, 10, 1)\n",
    "end_date = datetime.date(2023, 10, 1)\n",
    "\n",
    "total_projects = nih.count_projects_added_in_date_range(\n",
    "    start_date=parameters[\"start_date\"], end_date=parameters[\"end_date\"]\n",
    ")\n",
    "pbar = tqdm(\n",
    "    total=total_projects,\n",
    "    desc=f\"Projects from {parameters['start_date']} to {parameters['end_date']}\",\n",
    ")\n",
    "date_spine = [\n",
    "    parameters[\"start_date\"] + timedelta(days=x)\n",
    "    for x in range((parameters[\"end_date\"] - parameters[\"start_date\"]).days)\n",
    "]\n",
    "for date in date_spine:\n",
    "    pbar.write(f\"Retrieving projects for {date}\")\n",
    "    projects = nih.get_projects_by_day(date=date, add_timestamp_field=True)\n",
    "\n",
    "    if len(projects) > 0:  # process when there are projects\n",
    "        futuredf = []\n",
    "        for project in projects:\n",
    "            ai = structure_award_item(project)\n",
    "            pbar.update(1)\n",
    "\n",
    "            futuredf.append(asdict(ai))\n",
    "        if result_frame is None:\n",
    "            result_frame = pl.LazyFrame(futuredf)\n",
    "        else:\n",
    "            result_frame = pl.concat(\n",
    "                items=[result_frame, pl.LazyFrame(futuredf)], how=\"vertical_relaxed\"\n",
    "            )\n",
    "    else:  # no projects for this day\n",
    "        pass\n",
    "pbar.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_list.sink_parquet(\"data/nih.gov_grants.parquet\")\n",
    "result_list.sink_ndjson(\"data/nih.gov_grants.ndjson\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "oic-scrape-D2fotO-x-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
